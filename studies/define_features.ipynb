{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfc1fd7",
   "metadata": {},
   "source": [
    "# Defining features\n",
    "\n",
    "Here, I am going to define the features that will be used to establish similarity between books and how it is gonna be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7deabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef42caa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>editions id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>published year</th>\n",
       "      <th>rating</th>\n",
       "      <th>ratings</th>\n",
       "      <th>genres</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8492825</td>\n",
       "      <td>10706553</td>\n",
       "      <td>Where She Went</td>\n",
       "      <td>Gayle Forman</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.00</td>\n",
       "      <td>278348</td>\n",
       "      <td>[Young Adult, Romance, Contemporary, Fiction, ...</td>\n",
       "      <td>It's been three years since the devastating ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9961796</td>\n",
       "      <td>7149084</td>\n",
       "      <td>Lola and the Boy Next Door</td>\n",
       "      <td>Stephanie Perkins</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.93</td>\n",
       "      <td>159795</td>\n",
       "      <td>[Young Adult, Romance, Contemporary, Womens Fi...</td>\n",
       "      <td>Alternate Cove edition for ISBN 9780525423287L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8492856</td>\n",
       "      <td>13014066</td>\n",
       "      <td>What Happened to Goodbye</td>\n",
       "      <td>Sarah Dessen</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.94</td>\n",
       "      <td>87726</td>\n",
       "      <td>[Young Adult, Romance, Contemporary, Fiction, ...</td>\n",
       "      <td>Who is the real McLean?   Since her parents' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9464733</td>\n",
       "      <td>10808145</td>\n",
       "      <td>Beauty Queens</td>\n",
       "      <td>Libba Bray</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.62</td>\n",
       "      <td>56909</td>\n",
       "      <td>[Young Adult, Contemporary, Humor, Fiction, LG...</td>\n",
       "      <td>Teen beauty queens. A lost island. Mysteries a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8662836</td>\n",
       "      <td>13534308</td>\n",
       "      <td>Chain Reaction</td>\n",
       "      <td>Simone Elkeles</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.10</td>\n",
       "      <td>61978</td>\n",
       "      <td>[Romance, Young Adult, Contemporary, Realistic...</td>\n",
       "      <td>Luis Fuentes is a good boy who doesn't live wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>54860459</td>\n",
       "      <td>75186585</td>\n",
       "      <td>Hani and Ishu's Guide to Fake Dating</td>\n",
       "      <td>Adiba Jaigirdar</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.21</td>\n",
       "      <td>10835</td>\n",
       "      <td>[Romance, LGBT, Contemporary, Young Adult, LGB...</td>\n",
       "      <td>Everyone likes Humaira \"Hani\" Khan—she’s easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>54998272</td>\n",
       "      <td>71881363</td>\n",
       "      <td>The Girls I've Been</td>\n",
       "      <td>Tess Sharpe</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.18</td>\n",
       "      <td>12437</td>\n",
       "      <td>[Young Adult, LGBT, Thriller, Contemporary, My...</td>\n",
       "      <td>A slick, twisty YA page-turner about the daugh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>49204960</td>\n",
       "      <td>74656790</td>\n",
       "      <td>Perfect on Paper</td>\n",
       "      <td>Sophie Gonzales</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.13</td>\n",
       "      <td>10903</td>\n",
       "      <td>[Romance, Contemporary, Young Adult, LGBT, LGB...</td>\n",
       "      <td>In Perfect on Paper: a bisexual girl who gives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>49399658</td>\n",
       "      <td>73513987</td>\n",
       "      <td>Counting Down with You</td>\n",
       "      <td>Tashie Bhuiyan</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.17</td>\n",
       "      <td>10641</td>\n",
       "      <td>[Romance, Contemporary, Young Adult, Romance, ...</td>\n",
       "      <td>A reserved Bangladeshi teenager has twenty-eig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>53138093</td>\n",
       "      <td>66628056</td>\n",
       "      <td>The Project</td>\n",
       "      <td>Courtney Summers</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.53</td>\n",
       "      <td>9620</td>\n",
       "      <td>[Young Adult, Thriller, Mystery, Contemporary,...</td>\n",
       "      <td>Lo Denham is used to being on her own. After h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id editions id                                 title  \\\n",
       "0     8492825    10706553                        Where She Went   \n",
       "1     9961796     7149084            Lola and the Boy Next Door   \n",
       "2     8492856    13014066              What Happened to Goodbye   \n",
       "3     9464733    10808145                         Beauty Queens   \n",
       "4     8662836    13534308                        Chain Reaction   \n",
       "..        ...         ...                                   ...   \n",
       "215  54860459    75186585  Hani and Ishu's Guide to Fake Dating   \n",
       "216  54998272    71881363                   The Girls I've Been   \n",
       "217  49204960    74656790                      Perfect on Paper   \n",
       "218  49399658    73513987                Counting Down with You   \n",
       "219  53138093    66628056                           The Project   \n",
       "\n",
       "                author  published year  rating  ratings  \\\n",
       "0         Gayle Forman            2011    4.00   278348   \n",
       "1    Stephanie Perkins            2011    3.93   159795   \n",
       "2         Sarah Dessen            2011    3.94    87726   \n",
       "3           Libba Bray            2011    3.62    56909   \n",
       "4       Simone Elkeles            2011    4.10    61978   \n",
       "..                 ...             ...     ...      ...   \n",
       "215    Adiba Jaigirdar            2021    4.21    10835   \n",
       "216        Tess Sharpe            2021    4.18    12437   \n",
       "217    Sophie Gonzales            2021    4.13    10903   \n",
       "218     Tashie Bhuiyan            2021    4.17    10641   \n",
       "219   Courtney Summers            2021    3.53     9620   \n",
       "\n",
       "                                                genres  \\\n",
       "0    [Young Adult, Romance, Contemporary, Fiction, ...   \n",
       "1    [Young Adult, Romance, Contemporary, Womens Fi...   \n",
       "2    [Young Adult, Romance, Contemporary, Fiction, ...   \n",
       "3    [Young Adult, Contemporary, Humor, Fiction, LG...   \n",
       "4    [Romance, Young Adult, Contemporary, Realistic...   \n",
       "..                                                 ...   \n",
       "215  [Romance, LGBT, Contemporary, Young Adult, LGB...   \n",
       "216  [Young Adult, LGBT, Thriller, Contemporary, My...   \n",
       "217  [Romance, Contemporary, Young Adult, LGBT, LGB...   \n",
       "218  [Romance, Contemporary, Young Adult, Romance, ...   \n",
       "219  [Young Adult, Thriller, Mystery, Contemporary,...   \n",
       "\n",
       "                                              synopsis  \n",
       "0    It's been three years since the devastating ac...  \n",
       "1    Alternate Cove edition for ISBN 9780525423287L...  \n",
       "2    Who is the real McLean?   Since her parents' b...  \n",
       "3    Teen beauty queens. A lost island. Mysteries a...  \n",
       "4    Luis Fuentes is a good boy who doesn't live wi...  \n",
       "..                                                 ...  \n",
       "215  Everyone likes Humaira \"Hani\" Khan—she’s easy ...  \n",
       "216  A slick, twisty YA page-turner about the daugh...  \n",
       "217  In Perfect on Paper: a bisexual girl who gives...  \n",
       "218  A reserved Bangladeshi teenager has twenty-eig...  \n",
       "219  Lo Denham is used to being on her own. After h...  \n",
       "\n",
       "[220 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_pickle('../temp/ya-fiction-books-clean.pickle')\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a59b3",
   "metadata": {},
   "source": [
    "The features used to compare books and define similarities are going to be:\n",
    "- `author`\n",
    "- `genres`\n",
    "- `synopsis`\n",
    "\n",
    "The other features are going to be important, but, for now, we are going to mantain just those 3 columns and `id` and `title` for identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57770e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genres</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8492825</td>\n",
       "      <td>Where She Went</td>\n",
       "      <td>Gayle Forman</td>\n",
       "      <td>[Young Adult, Romance, Contemporary, Fiction, ...</td>\n",
       "      <td>It's been three years since the devastating ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9961796</td>\n",
       "      <td>Lola and the Boy Next Door</td>\n",
       "      <td>Stephanie Perkins</td>\n",
       "      <td>[Young Adult, Romance, Contemporary, Womens Fi...</td>\n",
       "      <td>Alternate Cove edition for ISBN 9780525423287L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8492856</td>\n",
       "      <td>What Happened to Goodbye</td>\n",
       "      <td>Sarah Dessen</td>\n",
       "      <td>[Young Adult, Romance, Contemporary, Fiction, ...</td>\n",
       "      <td>Who is the real McLean?   Since her parents' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9464733</td>\n",
       "      <td>Beauty Queens</td>\n",
       "      <td>Libba Bray</td>\n",
       "      <td>[Young Adult, Contemporary, Humor, Fiction, LG...</td>\n",
       "      <td>Teen beauty queens. A lost island. Mysteries a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8662836</td>\n",
       "      <td>Chain Reaction</td>\n",
       "      <td>Simone Elkeles</td>\n",
       "      <td>[Romance, Young Adult, Contemporary, Realistic...</td>\n",
       "      <td>Luis Fuentes is a good boy who doesn't live wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       title             author  \\\n",
       "0  8492825              Where She Went       Gayle Forman   \n",
       "1  9961796  Lola and the Boy Next Door  Stephanie Perkins   \n",
       "2  8492856    What Happened to Goodbye       Sarah Dessen   \n",
       "3  9464733               Beauty Queens         Libba Bray   \n",
       "4  8662836              Chain Reaction     Simone Elkeles   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [Young Adult, Romance, Contemporary, Fiction, ...   \n",
       "1  [Young Adult, Romance, Contemporary, Womens Fi...   \n",
       "2  [Young Adult, Romance, Contemporary, Fiction, ...   \n",
       "3  [Young Adult, Contemporary, Humor, Fiction, LG...   \n",
       "4  [Romance, Young Adult, Contemporary, Realistic...   \n",
       "\n",
       "                                            synopsis  \n",
       "0  It's been three years since the devastating ac...  \n",
       "1  Alternate Cove edition for ISBN 9780525423287L...  \n",
       "2  Who is the real McLean?   Since her parents' b...  \n",
       "3  Teen beauty queens. A lost island. Mysteries a...  \n",
       "4  Luis Fuentes is a good boy who doesn't live wi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = books[['id', 'title', 'author', 'genres', 'synopsis']]\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe6e97",
   "metadata": {},
   "source": [
    "## author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157853c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantity of books with more than one author (or contributor)\n",
    "books[books['author'].str.contains(',')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a199744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to separate authors/contributors and apply strip\n",
    "strip_func = lambda text: text.strip() # apply strip to a text\n",
    "strip_on_list = lambda list_: list(map(strip_func, list_)) # iterate over separated authors\n",
    "split_authors = lambda authors: strip_on_list(authors.split(',')) # split authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58667796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the vectorizer that is going to split authors and count its frequency per book\n",
    "authors_vectorizer = CountVectorizer(tokenizer=split_authors, lowercase=False)\n",
    "analyzer = authors_vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97d6353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachael Lippincott , Mikki Daughtry  , Tobias Iaconis\n",
      "['Rachael Lippincott', 'Mikki Daughtry', 'Tobias Iaconis']\n"
     ]
    }
   ],
   "source": [
    "# Quick example that takes a string with 3 authors and returns a list with them separated\n",
    "authors_sample = books[books['author'].str.contains(',')]['author'][160]\n",
    "\n",
    "print(authors_sample)\n",
    "print(analyzer(authors_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "911c47a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbi Glines</th>\n",
       "      <th>Adam Silvera</th>\n",
       "      <th>Adib Khorram</th>\n",
       "      <th>Adiba Jaigirdar</th>\n",
       "      <th>Aisha Saeed</th>\n",
       "      <th>Ali Novak</th>\n",
       "      <th>Alice Oseman</th>\n",
       "      <th>Ally Carter</th>\n",
       "      <th>Amber   Smith</th>\n",
       "      <th>Amber L.  Johnson</th>\n",
       "      <th>...</th>\n",
       "      <th>Tammara Webber</th>\n",
       "      <th>Tashie Bhuiyan</th>\n",
       "      <th>Tess Sharpe</th>\n",
       "      <th>Tiffany D. Jackson</th>\n",
       "      <th>Tillie Cole</th>\n",
       "      <th>Tobias Iaconis</th>\n",
       "      <th>Trish Doller</th>\n",
       "      <th>Wendelin Van Draanen</th>\n",
       "      <th>Yamile Saied Méndez</th>\n",
       "      <th>Yusef Salaam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Abbi Glines  Adam Silvera  Adib Khorram  Adiba Jaigirdar  Aisha Saeed  \\\n",
       "0            0             0             0                0            0   \n",
       "1            0             0             0                0            0   \n",
       "2            0             0             0                0            0   \n",
       "3            0             0             0                0            0   \n",
       "4            0             0             0                0            0   \n",
       "\n",
       "   Ali Novak  Alice Oseman  Ally Carter  Amber   Smith  Amber L.  Johnson  \\\n",
       "0          0             0            0              0                  0   \n",
       "1          0             0            0              0                  0   \n",
       "2          0             0            0              0                  0   \n",
       "3          0             0            0              0                  0   \n",
       "4          0             0            0              0                  0   \n",
       "\n",
       "   ...  Tammara Webber  Tashie Bhuiyan  Tess Sharpe  Tiffany D. Jackson  \\\n",
       "0  ...               0               0            0                   0   \n",
       "1  ...               0               0            0                   0   \n",
       "2  ...               0               0            0                   0   \n",
       "3  ...               0               0            0                   0   \n",
       "4  ...               0               0            0                   0   \n",
       "\n",
       "   Tillie Cole  Tobias Iaconis  Trish Doller  Wendelin Van Draanen  \\\n",
       "0            0               0             0                     0   \n",
       "1            0               0             0                     0   \n",
       "2            0               0             0                     0   \n",
       "3            0               0             0                     0   \n",
       "4            0               0             0                     0   \n",
       "\n",
       "   Yamile Saied Méndez  Yusef Salaam  \n",
       "0                    0             0  \n",
       "1                    0             0  \n",
       "2                    0             0  \n",
       "3                    0             0  \n",
       "4                    0             0  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the dataframe that contains the frequency of authors per book\n",
    "authors_count = authors_vectorizer.fit_transform(books['author']).toarray()\n",
    "authors_count_df = pd.DataFrame(data=authors_count, columns=authors_vectorizer.get_feature_names())\n",
    "authors_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80db141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kasie West            5\n",
       "Katie McGarry         5\n",
       "Sarah Dessen          5\n",
       "Maureen Johnson       5\n",
       "Becky Albertalli      5\n",
       "                     ..\n",
       "Justin A. Reynolds    1\n",
       "Julie Buxbaum         1\n",
       "Julie Berry           1\n",
       "Cynthia Hand          1\n",
       "Yusef Salaam          1\n",
       "Length: 147, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing the most and less common authors\n",
    "authors_count_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ffb5bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    95\n",
       "2    34\n",
       "3     8\n",
       "4     5\n",
       "5     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This a count of the count,\n",
    "# 95 books contains only 1 author\n",
    "# 34 books contains 2 authors\n",
    "# 08 books contains 3 authors\n",
    "# and so on\n",
    " authors_count_df.sum().sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07dbca",
   "metadata": {},
   "source": [
    "To finish, that dataframe is going to be one of the bases to establish similarity between books. Declaring that books with the same author are highly likely to look alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4db51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbi Glines</th>\n",
       "      <th>Adam Silvera</th>\n",
       "      <th>Adib Khorram</th>\n",
       "      <th>Adiba Jaigirdar</th>\n",
       "      <th>Aisha Saeed</th>\n",
       "      <th>Ali Novak</th>\n",
       "      <th>Alice Oseman</th>\n",
       "      <th>Ally Carter</th>\n",
       "      <th>Amber   Smith</th>\n",
       "      <th>Amber L.  Johnson</th>\n",
       "      <th>...</th>\n",
       "      <th>Tammara Webber</th>\n",
       "      <th>Tashie Bhuiyan</th>\n",
       "      <th>Tess Sharpe</th>\n",
       "      <th>Tiffany D. Jackson</th>\n",
       "      <th>Tillie Cole</th>\n",
       "      <th>Tobias Iaconis</th>\n",
       "      <th>Trish Doller</th>\n",
       "      <th>Wendelin Van Draanen</th>\n",
       "      <th>Yamile Saied Méndez</th>\n",
       "      <th>Yusef Salaam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Abbi Glines  Adam Silvera  Adib Khorram  Adiba Jaigirdar  Aisha Saeed  \\\n",
       "0              0             0             0                0            0   \n",
       "1              0             0             0                0            0   \n",
       "2              0             0             0                0            0   \n",
       "3              0             0             0                0            0   \n",
       "4              0             0             0                0            0   \n",
       "..           ...           ...           ...              ...          ...   \n",
       "215            0             0             0                1            0   \n",
       "216            0             0             0                0            0   \n",
       "217            0             0             0                0            0   \n",
       "218            0             0             0                0            0   \n",
       "219            0             0             0                0            0   \n",
       "\n",
       "     Ali Novak  Alice Oseman  Ally Carter  Amber   Smith  Amber L.  Johnson  \\\n",
       "0            0             0            0              0                  0   \n",
       "1            0             0            0              0                  0   \n",
       "2            0             0            0              0                  0   \n",
       "3            0             0            0              0                  0   \n",
       "4            0             0            0              0                  0   \n",
       "..         ...           ...          ...            ...                ...   \n",
       "215          0             0            0              0                  0   \n",
       "216          0             0            0              0                  0   \n",
       "217          0             0            0              0                  0   \n",
       "218          0             0            0              0                  0   \n",
       "219          0             0            0              0                  0   \n",
       "\n",
       "     ...  Tammara Webber  Tashie Bhuiyan  Tess Sharpe  Tiffany D. Jackson  \\\n",
       "0    ...               0               0            0                   0   \n",
       "1    ...               0               0            0                   0   \n",
       "2    ...               0               0            0                   0   \n",
       "3    ...               0               0            0                   0   \n",
       "4    ...               0               0            0                   0   \n",
       "..   ...             ...             ...          ...                 ...   \n",
       "215  ...               0               0            0                   0   \n",
       "216  ...               0               0            1                   0   \n",
       "217  ...               0               0            0                   0   \n",
       "218  ...               0               1            0                   0   \n",
       "219  ...               0               0            0                   0   \n",
       "\n",
       "     Tillie Cole  Tobias Iaconis  Trish Doller  Wendelin Van Draanen  \\\n",
       "0              0               0             0                     0   \n",
       "1              0               0             0                     0   \n",
       "2              0               0             0                     0   \n",
       "3              0               0             0                     0   \n",
       "4              0               0             0                     0   \n",
       "..           ...             ...           ...                   ...   \n",
       "215            0               0             0                     0   \n",
       "216            0               0             0                     0   \n",
       "217            0               0             0                     0   \n",
       "218            0               0             0                     0   \n",
       "219            0               0             0                     0   \n",
       "\n",
       "     Yamile Saied Méndez  Yusef Salaam  \n",
       "0                      0             0  \n",
       "1                      0             0  \n",
       "2                      0             0  \n",
       "3                      0             0  \n",
       "4                      0             0  \n",
       "..                   ...           ...  \n",
       "215                    0             0  \n",
       "216                    0             0  \n",
       "217                    0             0  \n",
       "218                    0             0  \n",
       "219                    0             0  \n",
       "\n",
       "[220 rows x 147 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06b84a",
   "metadata": {},
   "source": [
    "## genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4596913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     4\n",
       "12    31\n",
       "13    80\n",
       "14    76\n",
       "15    28\n",
       "16     1\n",
       "Name: genres, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Couting the frequency of genres by book\n",
    "# To understand: 04 books have 11 genres\n",
    "#                31 books have 12 genres\n",
    "#                and so on\n",
    "books['genres'].apply(len).sort_values(ascending=False).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4674b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with the frequency of each genre.\n",
    "# As each data from the genres columns are lists, the process here is different from the one with authors\n",
    "genres_columns = []\n",
    "genres_count_df = pd.DataFrame(index=books.index)\n",
    "\n",
    "for i, row in books.iterrows():\n",
    "    for genre in row['genres']:\n",
    "        if not genre in genres_count_df.columns:\n",
    "            genres_count_df[genre] = 0\n",
    "        genres_count_df.at[i, genre] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afce2d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Young Adult</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Contemporary</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Realistic Fiction</th>\n",
       "      <th>Music</th>\n",
       "      <th>New Adult</th>\n",
       "      <th>Teen</th>\n",
       "      <th>Audiobook</th>\n",
       "      <th>Young Adult Contemporary</th>\n",
       "      <th>...</th>\n",
       "      <th>Mythology</th>\n",
       "      <th>Greek Mythology</th>\n",
       "      <th>Islam</th>\n",
       "      <th>Muslims</th>\n",
       "      <th>Murder Mystery</th>\n",
       "      <th>Politics</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Christian Fiction</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Cults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Young Adult  Romance  Contemporary  Fiction  Realistic Fiction  Music  \\\n",
       "0            1        1             1        1                  1      1   \n",
       "1            1        1             1        1                  1      0   \n",
       "2            1        1             1        1                  1      0   \n",
       "3            1        1             1        1                  0      0   \n",
       "4            1        1             1        1                  1      0   \n",
       "\n",
       "   New Adult  Teen  Audiobook  Young Adult Contemporary  ...  Mythology  \\\n",
       "0          1     1          1                         1  ...          0   \n",
       "1          0     1          0                         1  ...          0   \n",
       "2          0     1          0                         1  ...          0   \n",
       "3          0     1          1                         0  ...          0   \n",
       "4          1     0          0                         0  ...          0   \n",
       "\n",
       "   Greek Mythology  Islam  Muslims  Murder Mystery  Politics  Christian  \\\n",
       "0                0      0        0               0         0          0   \n",
       "1                0      0        0               0         0          0   \n",
       "2                0      0        0               0         0          0   \n",
       "3                0      0        0               0         0          0   \n",
       "4                0      0        0               0         0          0   \n",
       "\n",
       "   Christian Fiction  Japan  Cults  \n",
       "0                  0      0      0  \n",
       "1                  0      0      0  \n",
       "2                  0      0      0  \n",
       "3                  0      0      0  \n",
       "4                  0      0      0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316059a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Young Adult                 200\n",
       "Fiction                     192\n",
       "Contemporary                189\n",
       "Romance                     168\n",
       "Realistic Fiction           146\n",
       "Young Adult Contemporary    128\n",
       "Audiobook                   116\n",
       "Teen                         72\n",
       "Contemporary Romance         56\n",
       "Young Adult Romance          56\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing the most common genres\n",
    "genres_count_df.sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d511781",
   "metadata": {},
   "source": [
    "Just like with the authors, we are going to use genres as a base to relate books. But we are gonna keep he genres \"Young Adult\" and \"Fiction\" out of our genres dataframe given that mostly books has those genres (obviously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e25f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_count_df.drop(['Young Adult', 'Fiction'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9b289",
   "metadata": {},
   "source": [
    "## synopsis\n",
    "\n",
    "Time of our most rich column in content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d530be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zine</th>\n",
       "      <th>zoboi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zorie</th>\n",
       "      <th>zurich</th>\n",
       "      <th>àbíké</th>\n",
       "      <th>étienne</th>\n",
       "      <th>íyímídé</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5715 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02  03  05  10  100  11  11th  12  ...  zhang  zillion  zine  \\\n",
       "0   0    0   0   0   0   0    0   0     0   0  ...      0        0     0   \n",
       "1   0    0   0   0   0   0    0   0     0   0  ...      0        0     0   \n",
       "2   0    0   0   0   0   0    0   0     0   0  ...      0        0     0   \n",
       "3   0    0   0   0   0   0    0   0     0   0  ...      0        0     0   \n",
       "4   0    0   0   0   0   0    0   0     0   0  ...      0        0     0   \n",
       "\n",
       "   zoboi  zone  zorie  zurich  àbíké  étienne  íyímídé  \n",
       "0      0     0      0       0      0        0        0  \n",
       "1      0     0      0       0      0        0        0  \n",
       "2      0     0      0       0      0        0        0  \n",
       "3      0     0      0       0      0        0        0  \n",
       "4      0     0      0       0      0        0        0  \n",
       "\n",
       "[5 rows x 5715 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using, again, a vectorizer to extract features from synopsis and create a dataframe\n",
    "synopsis_vectorizer = CountVectorizer()\n",
    "synopsis_count = synopsis_vectorizer.fit_transform(books['synopsis']).toarray()\n",
    "synopsis_count_df = pd.DataFrame(data=synopsis_count, columns=synopsis_vectorizer.get_feature_names())\n",
    "synopsis_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d1ce34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and     220\n",
       "the     219\n",
       "to      214\n",
       "of      209\n",
       "in      201\n",
       "is      188\n",
       "but     187\n",
       "her     174\n",
       "that    169\n",
       "for     168\n",
       "with    164\n",
       "she     149\n",
       "when    149\n",
       "it      148\n",
       "has     131\n",
       "on      125\n",
       "be      125\n",
       "an      120\n",
       "at      118\n",
       "who     118\n",
       "from    116\n",
       "as      114\n",
       "life    112\n",
       "he      111\n",
       "one     110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the frequency of the most used words between the books\n",
    "synopsis_occurrence = synopsis_count_df.copy()\n",
    "synopsis_occurrence[synopsis_occurrence > 1] = 1\n",
    "\n",
    "synopsis_sum = synopsis_occurrence.sum()\n",
    "\n",
    "synopsis_sum[synopsis_sum >= 220*0.5].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112587bd",
   "metadata": {},
   "source": [
    "On the final use, some of those words are going to be ignored, given that its meaning is really small, but I am going to keep some of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6232a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
